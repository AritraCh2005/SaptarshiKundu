name: Evaluate Model Submission

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'submissions/**'
      

  push:
    branches:
      - main
    paths:
      - 'submissions/**'

jobs:
  validate-submission:
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    outputs:
      username: ${{ steps.extract-info.outputs.username }}
      valid: ${{ steps.validate.outputs.valid }}
    steps:
      - uses: actions/checkout@v3
      
      - name: Extract submission info
        id: extract-info
        run: |
          PR_FILES=$(gh pr view ${{ github.event.pull_request.number }} --json files -q '.files[].path')
          USERNAME=$(echo "$PR_FILES" | grep -oP 'submissions/\K[^/]+' | head -1)
          echo "username=$USERNAME" >> $GITHUB_OUTPUT
        env:
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
      
      - name: Validate submission structure
        id: validate
        run: |
          USERNAME="${{ steps.extract-info.outputs.username }}"
          # Check if submission directory exists 
          if [ ! -d "submissions/$USERNAME" ]; then
            echo "::error::Invalid submission structure. Directory submissions/$USERNAME not found."
            echo "valid=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Check if model file exists
          MODEL_FILE=$(find "submissions/$USERNAME" -type f -name "model.*" | head -1)
          if [ -z "$MODEL_FILE" ]; then
            echo "::error::Model file not found in submissions/$USERNAME/"
            echo "valid=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Check model file extension
          if [[ ! "$MODEL_FILE" =~ \.(pt|pth|h5|pb|saved_model|tflite)$ ]]; then
            echo "::error::Invalid model format. Supported formats: .pt, .pth, .h5, .pb, .saved_model, .tflite"
            echo "valid=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Check if metadata.json exists
          if [ ! -f "submissions/$USERNAME/metadata.json" ]; then
            echo "::error::metadata.json not found in submissions/$USERNAME/"
            echo "valid=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Validate metadata.json format
          jq . "submissions/$USERNAME/metadata.json" > /dev/null 2>&1
          if [ $? -ne 0 ]; then
            echo "::error::Invalid metadata.json format"
            echo "valid=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # All checks passed
          echo "valid=true" >> $GITHUB_OUTPUT
          
  evaluate-model:
    runs-on: ubuntu-latest
    outputs:
      model_size: ${{ steps.evaluate.outputs.model_size }}
      latency: ${{ steps.evaluate.outputs.latency }}
      accuracy: ${{ steps.evaluate.outputs.accuracy }}
      total_score: ${{ steps.evaluate.outputs.total_score }}
    steps:
      - uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install torch torchvision tensorflow kaggle numpy pandas matplotlib
          
      - name: Download validation dataset
        run: |
          # Setup authentication - Method 1 (using just the credentials file)
          mkdir -p ~/.kaggle
          echo "{\"username\":\"${{ secrets.KAGGLE_USERNAME }}\",\"key\":\"${{ secrets.KAGGLE_KEY }}\"}" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json
          
          # Verify credentials file
          if [ ! -s ~/.kaggle/kaggle.json ]; then
            echo "::error::Kaggle credentials file is empty or not created"
            exit 1
          fi
          
          # Test API access before download
          echo "Testing Kaggle API access..."
          kaggle datasets list -s ${{ secrets.KAGGLE_DATASET }} || { echo "::error::Failed to access Kaggle API"; exit 1; }
          
          # Download dataset with error handling
          echo "Downloading dataset..."
          kaggle datasets download -d ${{ secrets.KAGGLE_DATASET }} -p ./data --unzip || { echo "::error::Failed to download dataset"; exit 1; }
          
          # Check if files were actually downloaded
          if [ ! "$(ls -A ./data)" ]; then
            echo "::error::Dataset directory is empty after download"
            exit 1
          fi
          
          echo "Dataset download completed successfully"
          
      - name: Evaluate model
        id: evaluate
        run: |
          # USERNAME="${{ needs.validate-submission.outputs.username }}"
          USERNAME="baseline"
          python scripts/evaluate.py \
            --submission_dir "submissions/$USERNAME" \
            --data_dir "./data" \
            --baseline_size 44.7 \
            --baseline_latency 23.5 \
            --baseline_accuracy 69.76 \
            --output_file "evaluation_result.json"
          
          # Extract evaluation results
          MODEL_SIZE=$(jq -r '.model_size' evaluation_result.json)
          LATENCY=$(jq -r '.latency' evaluation_result.json)
          ACCURACY=$(jq -r '.accuracy' evaluation_result.json)
          TOTAL_SCORE=$(jq -r '.total_score' evaluation_result.json)
          
          # Set outputs
          echo "model_size=$MODEL_SIZE" >> $GITHUB_OUTPUT
          echo "latency=$LATENCY" >> $GITHUB_OUTPUT
          echo "accuracy=$ACCURACY" >> $GITHUB_OUTPUT
          echo "total_score=$TOTAL_SCORE" >> $GITHUB_OUTPUT
          
  update-leaderboard:
    # needs: [validate-submission, evaluate-model]
    needs: [evaluate-model]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas tabulate
          
      - name: Update leaderboard
        run: |
          USERNAME="${{ needs.validate-submission.outputs.username }}"
          MODEL_SIZE="${{ needs.evaluate-model.outputs.model_size }}"
          LATENCY="${{ needs.evaluate-model.outputs.latency }}"
          ACCURACY="${{ needs.evaluate-model.outputs.accuracy }}"
          TOTAL_SCORE="${{ needs.evaluate-model.outputs.total_score }}"
          SUBMISSION_DATE=$(date -u "+%Y-%m-%d %H:%M:%S UTC")
          
          python scripts/update_leaderboard.py \
            --username "$USERNAME" \
            --model_size "$MODEL_SIZE" \
            --latency "$LATENCY" \
            --accuracy "$ACCURACY" \
            --total_score "$TOTAL_SCORE" \
            --submission_date "$SUBMISSION_DATE" \
            --leaderboard_file "LEADERBOARD.md"
            
      - name: Commit and push leaderboard update
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add LEADERBOARD.md
          git commit -m "Update leaderboard with submission from ${{ needs.validate-submission.outputs.username }}"
          git push 